{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "metadata_generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1Vj_O3H2mC0"
      },
      "source": [
        "### CREATION OF METADATA TO BE USED IN PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxPRaiUDYmfE",
        "outputId": "c50862d6-9b99-4ad0-91c4-35d45b0df098"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2AQN2URjpiF",
        "outputId": "2747bc7d-d931-48dd-a529-47b260356ad0"
      },
      "source": [
        "#changing the working directory\n",
        "cd '/content/drive/MyDrive/speech _to _text'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/speech _to _text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtNqJ8qpkeG6"
      },
      "source": [
        "# import libraries\n",
        "import os\n",
        "from scipy.io import wavfile\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import logging\n",
        "import wave\n",
        "import contextlib\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjx85vRpXQ0O"
      },
      "source": [
        "logging.basicConfig(filename='..\\logs\\model.log', filemode='w', format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_VuiSIDo0h4"
      },
      "source": [
        "\n",
        "directory='/content/drive/MyDrive/Week-4/speech_data/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav'\n",
        "files=[]\n",
        "target='/content/drive/MyDrive/speech _to _text/data/alldata'\n",
        "def files_to_one_folder():\n",
        "  logging.info(\"===================== copying files from different folders to one folder ==================== \\n\")\n",
        "\n",
        "  for folders in os.listdir(directory):\n",
        "    #accessing subfolders inside train/wav directory\n",
        "    subfolder = os.path.join(directory,folders)\n",
        "    #looping through all contents in the subfolder\n",
        "    for wavz in os.listdir(subfolder):\n",
        "      files.append(wavz)\n",
        "      finalpath = os.path.join(subfolder,wavz)\n",
        "      # copying files\n",
        "      shutil.copy(finalpath, target)\n",
        "      print('==========DONE COPYING FILES===========/n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq80rFX3sy_h"
      },
      "source": [
        "#extracting text file and create transcriptions with their corresponding file names\n",
        "def get_trans_labels():\n",
        "  logging.info(\"===================== extracting transcripts and labels from txt file ==================== \\n\")\n",
        "  \n",
        "  with open ('/content/drive/MyDrive/Week-4/speech_data/ALFFA_PUBLIC/ASR/SWAHILI/data/train/text.txt', encoding=\"utf-8\")as f:\n",
        "    lines = f.readlines()\n",
        "  name=[] \n",
        "  text =[]\n",
        "  name_text={}\n",
        "  for line in lines :\n",
        "    for elements in line.split(\" \", 0):\n",
        "      b = elements.split('\\t')\n",
        "      # name.append(b[0] +'.wav')\n",
        "      name.append(b[0] )\n",
        "      text.append(b[1].split('\\n')[0])\n",
        "      name_text[b[0] +'.wav']=b[1].split('\\n')[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkegf6vaevZv"
      },
      "source": [
        "\n",
        "#calculate duration of audios\n",
        "def audio_duration():\n",
        "\n",
        "  logging.info(\"===================== calculating the duration of each audio file  ==================== \\n\")\n",
        "\n",
        "  duration_of_recordings=[]\n",
        "  for file in os.listdir(target):\n",
        "    with contextlib.closing(wave.open(target+'/'+file,'r')) as f:\n",
        "      frames = f.getnframes()\n",
        "      rate = f.getframerate()\n",
        "      duration = frames / float(rate)\n",
        "      duration_of_recordings.append(round(duration, 2))\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn98-rikuI4p"
      },
      "source": [
        "# creating a cvs file of file name with its corresponding text and its duration\n",
        "def metadata():\n",
        "  logging.info(\"======= # creating a cvs file of file name with its corresponding text and its duration ================= \\n\")\n",
        "  # creating a list of files\n",
        "  files=[]\n",
        "  #getting files from their directory\n",
        "  for file in os.listdir(target):\n",
        "    files.append(file)\n",
        "  # creating a dataframe \n",
        "  data=pd.DataFrame({'name_of_audio_file': files  ,'text': text, 'duration':duration_of_recordings})\n",
        "  # saving the dataframe to a choosen directory\n",
        "  data.to_csv(\"/content/drive/MyDrive/speech _to _text/data/merged_audio_data.csv\",index=False)\n",
        "  print(data.head(10))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQylpWcR3C9s",
        "outputId": "d7406ba1-901f-4deb-d2ca-a5736f0330f4"
      },
      "source": [
        "#CALLING FUNCTIONS\n",
        "if (__name__== '__main__'):\n",
        "    # files_to_one_folder()\n",
        "    get_trans_labels()\n",
        "    audio_duration()\n",
        "    metadata()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                  name_of_audio_file  ... duration\n",
            "0  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     3.14\n",
            "1  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     3.10\n",
            "2  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     3.65\n",
            "3  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     3.90\n",
            "4  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     2.94\n",
            "5  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     2.45\n",
            "6  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     2.62\n",
            "7  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     2.48\n",
            "8  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     3.53\n",
            "9  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     2.74\n",
            "\n",
            "[10 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}